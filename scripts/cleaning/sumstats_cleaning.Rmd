---
title: "rg results summary tables template"
author: "Abigail ter Kuile"
date: "28/08/2021"
output: html_document
---

# Rmd set up
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      comment=NA,
                      prompt=FALSE,
                      cache=FALSE)
```

Clear global environment
```{r Clear global environment}
remove(list = ls())
```

Package setup
```{r Packages}
#devtools::install_github("johanzvrskovec/shru")
library(optparse)
library(data.table)
library(summarytools)
library(shru)
library(googlesheets4)
library(tidyverse)
```

## Command line set up
```{r command line setup}
clParser <- OptionParser()

clParser <- add_option(
  object = clParser,
  opt_str = c("-t", "--task"),
  type= "character",
  default="clean",
  help = "The explicit task to run:\nclean: Clean GWAS sumstat [default %default]"
  )

clParser <- add_option(
  object = clParser,
  opt_str = c("-f", "--file"),
  type = "character",
  help="The file to process"
  )

clParser <- add_option(
  object = clParser,
  opt_str = c("-c", "--code"),
  type = "character",
  help = "The code to use for the dataset from the specified file."
  )

clParser <- add_option(
  object = clParser,
  opt_str = c("-n", "--sample-size"),
  type = "numeric",
  help = "Number of individuals in the sample."
  )

clOptions <- parse_args(clParser)
```

Retrieve the recent date
We use this to save files with a time stemp.
```{r Recent date}
date = Sys.Date()
date
```

Specify file name
This file name is needed to export the whole file as an R file
```{r Specify file name}
filename.rmd <- "sumstats_cleaning.Rmd"
```

## Source credentials files
This file includes the file path to the King's College London Microsoft Teams channel to store the raw data files of the GWAS summary statistics (intermediate solution before we move the final version to the rosalind cluster). However, we probably will save all summary statistics raw files on SharePoint/Teams to save space on rosalind.
sumstats_path

The file also contains the login details for your google work account: google_account_details

```{r Credentials file}
source(file = "../credentials/credentials.R")
```


# GWAS summary statistics overview sheet

Login to googlesheets
```{r Login to google sheets}
gs4_auth(email = google_account_details)
```


Import google spreadsheet that contains the information of the GWAS
```{r Google spreadsheet of GWAS dictionary}
gwas_sheet <- read_sheet(
  ss = "https://docs.google.com/spreadsheets/d/1Wmj4Qzumkzks6541vQJqxaUBxjfL4KLQo7_K_oquacI/edit#gid=0",
  sheet = "SGDP_GWASLIST_EDITTHIS",
  col_names = TRUE,
  trim_ws = TRUE, # Trims whitespace,
  guess_max = 600,
  na = c("", "NULL", "NA")
  )

colnames(gwas_sheet)

gwas_sheet
```

## Script settings

### Paths
A list of file paths you want to be processed in parallel. In the function this will be a list, but for the command line utility we have to parse the argument, maybe have paths separated by comma or similar?
_Set your file path_, when testing
```{r Paths}
filePaths <- c(
  paste0(sumstats_path, "/data_raw/CUD_EUR_full_public_11.14.2020.gz")
  ) 
# filePaths <- clOptions$file
```

### Trait names
A list of nice trait names which could be fit for a publication table/graph/plot
_Set your nice trait name_, when testing
```{r Trait names}
traitNames <- c("Cannabis use disorder (2020)") 
#traitNames <- clOptions$names
```

### Code
A list of codes you want to identify your traits by (different from the nice names), used to reference a trait by a string
These codes consist of 4 letters; for examples investigate the GWAS spreadsheet. Try to identify similar traits.
 #Set your trait code string_, when testing
```{r Code}
traitCodes <- c("CUDI01")
#traitCodes <- clOptions$code
```

### Creating the sumstats.meta object
Sumatats.meta is an output containing an overview with information of the cleaning steps that is generated throughout the cleaning pipeline for each GWAS trait.
```{r Creating the sumstats.meta object}
sumstats.meta <- data.frame(
  name = traitNames
  )

row.names(sumstats.meta) <- traitCodes
```

### Sample size
Explicitly set total N (e.g., a vector of sample sizes)
```{r Sample size}
cN <- clOptions$`sample-size`
```

### Indels
Setting for keeping or removing indels
```{r Sample size}
keepIndel <- FALSE # or change to TRUE
```

### MHC filter
Activate/deactivate MHC filter
```{r Sample size}
mhc.filter <- 37
```

### Supemunge?
Activate/deactivate supermunge
```{r Supermunge setting}
doSupermunge <- T
```


### R script export
Running this will produce an R script with the same name as the Rmd file.
+++CH: Do we really need this in this script or should this be a separate file?
```{r Purl export, include=FALSE, purl=FALSE, eval=FALSE}
knitr::purl(filename.rmd)
```

+++CH: Maybe we want to put this functions in separate R scripts and source them like we do in the other scripts?

### Standardised colum names
This chunk creates one function called "standardise_GWAS_column_names". The function interprets the columns of the original raw GWAS summary statistics and replaces them with standard column names. The standard column names are the first item in the vector:
SNP	CHR	ORIGBP	A1	A2	FREQ	FREQ_CASES	P	INFO	OR/BETA/Z	SE	N	Ncas	Ncon
We have chosen ORIGBP as output name, because the summary statistics are based on different genome builds which means SNPs will be located at different BPs
To avoid follow-up software using the BP column (cave: different genome builds), we named it ORIGBP.
The function stops if the essential columns SNP, A1, A2, P, BETA or OR or Z 

_Future_
+++CH: FREQ_CASES is missing when reading in, NEF is missing when reading in
+++CH: Ollie has code that detects the genome build of sumstats; we could add the chunk for lifting over. (not top priority).
+++CH: Johan, can you try to find the most recent version of Helena's script on the virtual machine?
+++CH: The stopping and the warning needs to be double checked. I think at the moment it only stops for SNP, A1 or A2 and nothing else.
```{r Standardise GWAS column names}
standardise_GWAS_column_names <- function(column_names, stop_on_missing_essential_column = T,
     c.SNP = c(
       "SNP",
       "PREDICTOR",
       "SNPID",
       "MARKERNAME",
       "MARKER_NAME",
       "SNPTESTID",
       "ID_DBSNP49",
       "RSID",
       "ID",
       "RS_NUMBER",
       "MARKER",
       "RS",
       "RSNUMBER",
       "RS_NUMBERS",
       "SNP.NAME",
       "SNP ID",
       "SNP_ID",
       "LOCATIONALID",
       "ASSAY_NAME"
       ),
     c.A1 = c(
       "A1",
       "ALLELE1",
       "ALLELE_1",
       "INC_ALLELE",
       "EA",
       "A1_EFFECT",
       "REF",
       "EFFECT_ALLELE",
       "RISK_ALLELE",
       "EFFECTALLELE",
       "EFFECT_ALL",
       "REFERENCE_ALLELE",
       "REF_ALLELE",
       "REFERENCEALLELE",
       "EA",
       "ALLELE_1",
       "INC_ALLELE",
       "ALLELE1",
       "A",
       "A_1",
       "CODED_ALLELE",
       "TESTED_ALLELE"
       ),
     c.A2 = c(
       "A2",
       "ALLELE2",
       "ALLELE_2",
       "OTHER_ALLELE",
       "NON_EFFECT_ALLELE",
       "DEC_ALLELE",
       "OA",
       "NEA",
       "ALT",
       "A2_OTHER",
       "NONREF_ALLELE",
       "NEFFECT_ALLELE",
       "NEFFECTALLELE",
       "NONEFFECT_ALLELE",
       "OTHER_ALL",
       "OTHERALLELE",
       "NONEFFECTALLELE",
       "ALLELE0",
       "ALLELE_0",
       "ALT_ALLELE",
       "A_0",
       "NONCODED_ALLELE"
       ),
     #c.EFFECT = c(
     #"EFFECT",
     #"OR",
     #"B",
     #"BETA",
     #"LOG_ODDS",
     #"EFFECTS",
     #"SIGNED_SUMSTAT",
     #"EST"
     #),
     c.BETA = c(
       "BETA",
       "B",
       "EFFECT_BETA",
       "EFFECT",
       "EFFECTS",
       "SIGNED_SUMSTAT",
       "EST",
       "GWAS_BETA",
       "EFFECT_A1",
       "EFFECTA1",
       "EFFECT_NW"
       ),
     c.OR = c(
       "OR",
       "LOG_ODDS",
       "OR",
       "ODDS-RATIO",
       "ODDS_RATIO",
       "ODDSRATIO",
       "OR(MINALLELE)",
       "OR.LOGISTIC",
       "OR_RAN",
       "OR(A1)"
       ),
     c.SE = c(
       "SE",
       "STDER",
       "STDERR",
       "STD",
       "STANDARD_ERROR",
       "OR_SE",
       "STANDARDERROR",
       "STDERR_NW",
       "META.SE",
       "SE_DGC",
       "SE.2GC"
       ),
     c.Z = c(
       "Z",
       "ZSCORE",
       "Z-SCORE",
       "ZSTAT",
       "ZSTATISTIC",
       "GC_ZSCORE",
       "BETAZSCALE"
       ),
     c.INFO = c(
       "INFO",
       "IMPINFO",
       "IMPQUALITY",
       "INFO.PLINK",
       "INFO_UKBB"
       ),
     c.P = c(
       "P",
       "PVALUE",
       "PVAL",
       "P_VALUE",
       "GC_PVALUE",
       "WALD_P",
       "P.VAL",
       "GWAS_P",
       "P-VALUE",
       "P-VAL",
       "FREQUENTIST_ADD_PVALUE",
       "P.VALUE",
       "P_VAL",
       "SCAN-P",
       "P.LMM",
       "META.PVAL",
       "P_RAN",
       "P.ADD",
       "P_BOLT_LMM"
       ),
     c.N = c(
       "N",
       "WEIGHT",
       "NCOMPLETESAMPLES",
       "TOTALSAMPLESIZE",
       "TOTALN",
       "TOTAL_N",
       "N_COMPLETE_SAMPLES",
       "N_TOTAL",
       "N_SAMPLES",
       "N_ANALYZED",
       "NSAMPLES",
       "SAMPLESIZE",
       "SAMPLE_SIZE",
       "TOTAL_SAMPLE_SIZE",
       "TOTALSAMPLESIZE"
       ),
     c.N_CAS = c(
       "Ncas",
       "N_CAS",
       "NCASE",
       "N_CASE",
       "N_CASES",
       "NCAS",
       "NCA",
       "NCASES",
       "CASES",
       "CASES_N",
       "FRQ_A" # +++CH: Is this correct here?
       ),
     c.N_CON = c(
       "Ncon",
       "N_CON",
       "NCONTROL",
       "N_CONTROL",
       "N_CONTROLS",
       "NCON",
       "NCO",
       "N_CON",
       "NCONTROLS",
       "CONTROLS",
       "CONTROLS_N",
       "FRQ_U" # +++CH: Is this correct here?
       ),
     c.NEF = c(
       "NEF",
       "NEFF",
       "NEFFECTIVE",
       "NE"
       ),
     #include FRQ_A? # +++CH: Who is this question by?
     c.FRQ = c(
       "FREQ",
       "FRQ",
       "MAF",
       "AF",
       "CEUAF",
       "FREQ1",
       "EAF",
       "FREQ1.HAPMAP",
       "FREQALLELE1HAPMAPCEU",
       "FREQ.ALLELE1.HAPMAPCEU",
       "EFFECT_ALLELE_FREQ",
       "FREQ.A1",
       "F_A",
       "F_U",
       "FREQ_A",
       "FREQ_U",
       "MA_FREQ",
       "MAF_NW",
       "FREQ_A1",
       "A1FREQ",
       "CODED_ALLELE_FREQUENCY",
       "FREQ_TESTED_ALLELE_IN_HRS",
       "EAF_HRC"
       ),
     c.CHR = c(
       "CHR",
       "CH",
       "CHROMOSOME",
       "CHROM",
       "CHR_BUILD38",
       "CHR_BUILD37",
       "CHR_BUILD36",
       "CHR_B38",
       "CHR_B37",
       "CHR_B36",
       "CHR_ID",
       "SCAFFOLD",
       "HG19CHR",
       "CHR.HG19",
       "CHR_HG19",
       "HG18CHR",
       "CHR.HG18",
       "CHR_HG18",
       "CHR_BP_HG19B37",
       "HG19CHRC"
       ),
     c.BP = c(
       "ORIGBP",
       "BP",
       "POS",
       "POSITION",
       "LOCATION",
       "PHYSPOS",
       "GENPOS",
       "CHR_POSITION",
       "POS_B38",
       "POS_BUILD38",
       "POS_B37",
       "POS_BUILD37",
       "BP_HG19B37",
       "POS_B36",
       "POS_BUILD36",
       "POS.HG19",
       "POS.HG18",
       "POS_HG19",
       "POS_HG18",
       "BP_HG19",
       "BP_HG18",
       "BP.GRCH38",
       "BP.GRCH37",
       "POSITION(HG19)",
       "POSITION(HG18)",
       "POS(B38)",
       "POS(B37)"
       )
                                       ){

  #column_names<-cSumstats.names #+++CH: Why is this hashed out?
  
  column_names.upper <- toupper(column_names)
  #names(column_names)<-column_names #+++CH: Why is this hashed out?
  column_names.orig <- column_names
  
  #+++CH: What does this bit do?
  column_names[column_names.upper %in% c.SNP] <- c.SNP[1]
  column_names[column_names.upper %in% c.A1] <- c.A1[1]
  column_names[column_names.upper %in% c.A2] <- c.A2[1]
  #column_names[column_names.upper %in% c.EFFECT] <- c.EFFECT[1] #+++CH: Why is this hashed out?
  #if(any(column_names==c.EFFECT[1])) column_names[column_names.upper %in% c.Z] <- c.Z[1] else column_names[column_names.upper %in% c.Z] <- c.EFFECT[1] #+++CH: Why is this hashed out?
  column_names[column_names.upper %in% c.BETA] <- c.BETA[1]
  column_names[column_names.upper %in% c.OR] <- c.OR[1] 
  column_names[column_names.upper %in% c.Z] <- c.Z[1] 
  column_names[column_names.upper %in% c.SE] <- c.SE[1]
  column_names[column_names.upper %in% c.INFO] <- c.INFO[1]
  column_names[column_names.upper %in% c.P] <- c.P[1]
  column_names[column_names.upper %in% c.N] <- c.N[1]
  column_names[column_names.upper %in% c.N_CAS] <- c.N_CAS[1]
  column_names[column_names.upper %in% c.N_CON] <- c.N_CON[1]
  column_names[column_names.upper %in% c.NEF] <- c.NEF[1]
  column_names[column_names.upper %in% c.FRQ] <- c.FRQ[1]
  column_names[column_names.upper %in% c.CHR] <- c.CHR[1]
  column_names[column_names.upper %in% c.BP] <- c.BP[1]
  
  if(stop_on_missing_essential_column){
# Stop if any of these columns are not found
    if(!any(column_names=="SNP")) stop("\nCould not find the 'SNP' column.\n")
    if(!any(column_names=="A1")) stop("\nCould not find the 'A1' column.\n")
    if(!any(column_names=="A2")) stop("\nCould not find the 'A2' column.\n")
    if(!any(column_names=="BETA") & !any(column_names=="OR") & !any(column_names=="Z")) stop("Could not find any effect column.\n")  
  }
  
  if(!any(column_names=="P")) warning("\nCould not find the P-value column. Standard is 'P'.\n")
  if(!any(column_names=="FRQ")) warning("\nCould not find the 'FRQ' column.\n")
  
# Warn if multiple of these columns are found #+++CH: Do we want to add more checks for duplicates?
  if(sum(column_names=="SNP")>1) warning("\nMultiple 'SNP' columns found!\n")
  if(sum(column_names=="P")>1) warning("\nMultiple 'P' columns found!\n")
  if(sum(column_names=="A1")>1) warning("\nMultiple 'A1' columns found!\n")
  if(sum(column_names=="A2")>1) warning("\nMultiple 'A2' columns found!\n")
  if(sum(column_names=="BETA")>1) warning("\nMultiple 'BETA' columns found!\n")
  if(sum(column_names=="OR")>1) warning("\nMultiple 'OR' columns found!\n")
  if(sum(column_names=="Z")>1) warning("\nMultiple 'Z' columns found!\n")
  if(sum(column_names=="SE")>1) warning("\nMultiple 'SE' columns found!\n")
  if(sum(column_names=="FRQ")>1) warning("\nMultiple 'FRQ' columns found!\n")
  if(sum(column_names=="INFO")>1) warning("\nMultiple 'INFO' columns found!\n")
  
  return(
    data.frame(
      std = column_names,
      orig = column_names.orig
      )
    )
}
```

# Chromosome numbering
We are changing naming of chromosomes to PLINK standard.
As a reference, we are using the PLINK naming:
plink chromosome numbering: https://zzz.bwh.harvard.edu/plink/data.shtml

_Future_
+++CH: These functions need a sentence explaining what they are doing. Who is going to do this?
+++CH: What is this comment about the number of SNPs? Can we move this outside of the chunk including explanation?
+++JKZ: It only checks the top 100,000 SNPs in a file. We don't know what happens if it detects less than 100,000
```{r Chromosome numbering}
parseSNPColumnAsRSNumber <- function(text){
  #decide if BGENIE SNP format using top 100,000 SNPs
  #TODO this condition may be improved to not rely on the number of variants being >100,000
  #test
  #text<-files[[i]]$SNP
  if(sum(grepl(pattern = "^\\d+:\\w+_\\w+_\\w+", x= head(x = text, n=100000)))>90000){
    #extract and format rs-no
    indexesLengths<-regexec(pattern = "^\\d+:(\\w+)_\\w+_\\w+", text=text)
    matches<-regmatches(text,indexesLengths)
    return(lapply(X = matches, FUN = function(x)paste0("rs",x[2])))
  }
  
  text<-sub(pattern = "^XY:",replacement = "25:",x = text)
  text<-sub(pattern = "^X:",replacement = "23:",x = text)
  text<-sub(pattern = "^Y:",replacement = "24:",x = text)
  text<-sub(pattern = "^MT:",replacement = "26:",x = text)
  text<-sub(pattern = "^chr",replacement = "",x = text)
  text<-sub(pattern = "_",replacement = ":",x = text)
  
  return(text)
}

parseCHRColumn <- function(text){
  text<-sub(pattern = "^XY",replacement = "25",x = text)
  text<-sub(pattern = "^X",replacement = "23",x = text)
  text<-sub(pattern = "^Y",replacement = "24",x = text)
  text<-sub(pattern = "^MT",replacement = "26",x = text)
  text<-sub(pattern = "^chr",replacement = "",x = text)
  return(text)
}
```



## Read in sumstats and interpret columns
We use the data.table package, because it is much faster than the basic R functions to read in data.
https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html

_Future_
+++JZ: TODO replace commas with field separators as in Helena's script
+++CH: Has this happened?
```{r read in sumstats}
cCode <- traitCodes[1]

cFilePath <- filePaths[1] #we will probably want to have a loop over the provided files
# For Ollie testng:
# cFilePath<-'/users/k1806347/brc_scratch/Data/GWAS_sumstats/Rosalind_repository/CUD_EUR_full_public_11.14.2020.gz'
cSumstats <- data.table::fread(
  file = cFilePath,
  header = T,
  quote = "\"",
  fill = T, # If TRUE then in case the rows have unequal length, blank fields are implicitly filled.
  na.strings = c(
    ".",
    NA,
    "NA",
    ""
    )
  )

#number of rows before touching the data
nRowsRaw <- nrow(cSumstats)
sumstats.meta[cCode,c("n_snp_raw")]<-nRowsRaw #add number of SNPs raw to sumstats.meta (meta data file)

sumstats.meta$n_snp_raw
```

## Interpret columns
Checks the existence of columns based on list of column names in chunk above (Standardise GWAS column names). Renames columns to standardised names.
```{r interpret columns}
newNames <- standardise_GWAS_column_names(
  column_names = colnames(cSumstats)
  )
print(newNames)
colnames(cSumstats) <- as.character(newNames$std)
```

# Column and dataframe re-formatting

## Re-format and parse special format columns
Set correct R data formats

Transform to data table
```{r Transform to data table}
cSumstats <- setDT(cSumstats)
```

Clean or fix variant SNP column
```{r Fix SNP column}
cSumstats.keys <- c('SNP')
cSumstats$SNP <- as.character(cSumstats$SNP)
```

Format A1 and A2 to upper case
```{r Format A1 and A2 to upper case}
cSumstats$A1 <- toupper(as.character(cSumstats$A1))
cSumstats$A2 <- toupper(as.character(cSumstats$A2))
```

Parse SNP (if needed)
```{r Parse SNP}
cSumstats$SNP <- tolower(parseSNPColumnAsRSNumber(cSumstats$SNP))

if(any(colnames(cSumstats)=="CHR")) {
  cSumstats$CHR <- toupper(as.character(cSumstats$CHR))
  cSumstats.keys <- c(cSumstats.keys,'CHR')
}

if(any(colnames(cSumstats)=="BP")) {
  cSumstats$BP <- as.integer(cSumstats$BP)
  cSumstats.keys <- c(cSumstats.keys,'BP')
}
```

Set data table index on selected keys
+++CH: Johan, what does this do, please explain
+++OP: Seems to sort the data table and index by SNP id to allow faster manipulations downstream. Not certain though!
```{r Set data table index on selected keys}
setkeyv(cSumstats,cols = cSumstats.keys)
```


Interpret BGENIE SNP format

Check if daner like columns present
ref: https://docs.google.com/document/d/1TWIhr8-qpCXB13WCXcU1_HDio8lC_MeWoAg2jlggrtU/edit
```{r Interpret daner like format}
if(!any(colnames(cSumstats)=="FRQ") & !any(colnames(cSumstats)=="N_CAS") & !any(colnames(cSumstats)=="N_CON")){
  danerNcas<-colnames(cSumstats)[startsWith(colnames(cSumstats),prefix = "FRQ_A_")][1]
  danerNcon<-colnames(cSumstats)[startsWith(colnames(cSumstats),prefix = "FRQ_U_")][1]
  if(!is.na(danerNcas) & !is.na(danerNcon)){
    #add number of cases and number of controls
    cSumstats$N_CAS <- danerNcas
    cSumstats$N_CON <- danerNcon
    #add case and control specific effect allele frequencies
    colnames(cSumstats)[danerNcas] <- "FRQ_CASES"
    colnames(cSumstats)[danerNcon] <- "FRQ_CONTROLS"
  }
  
}
```


Rename duplicate columns
Deal with duplicate columns - use the first occurrence
```{r Rename duplicate columns}
##SNP
iDup<-grep(pattern = "^SNP$",colnames(cSumstats))
if(length(iDup)>1){
  iDup<-iDup[2:length(iDup)]
  colnames(cSumstats)[iDup]<-"XSNP"
}

##BP
if('BP' %in% names(cSumstats)){
  iDup<-grep(pattern = "^BP$",colnames(cSumstats))
  if(length(iDup)>1){
    iDup<-iDup[2:length(iDup)]
    colnames(cSumstats)[iDup]<-"XBP"
  }
}

##FRQ
if('FRQ' %in% names(cSumstats)){
  iDup<-grep(pattern = "^FRQ$",colnames(cSumstats))
  if(length(iDup)>1){
    iDup<-iDup[2:length(iDup)]
    colnames(cSumstats)[iDup]<-"XFRQ"
  }
}
```


+++JZ: DO WE WANT TO CONVERT CHR TO NUMERIC VALUES?
+++OP: No strong opinion on this. Are there standard numeric values for non-autosomes and what does commonly used software use? If not then I would suggest leaving as a character vector.
```{r Convert to numeric columns}

```


# Add missing columns

## Add total N depending on columns and input
1) Calcualte N from Ncon and Ncas, if not present
2) Set N from external argument (set at the beginning)

Add columns on sample size, enough for PRS enough for pathway analysis

```{r add missing N columns}
if(any(colnames(cSumstats)=="N_CAS") && any(colnames(cSumstats)=="N_CON")) {
  ### Calculate total N from number of cases and number of controls if they are present. Overwrite any specific total N.
  cSumstats$N <- cSumstats$N_CAS + cSumstats$N_CON
} else if(!is.null(cN)) {
  cSumstats$N[which(is.na(cSumstats$N))]<-cN #default behaviour - add explicit N only to missing values.
} else if(!any(colnames(cSumstats)=="N")) {
  warning("\nNo N column detected!\n")
  sumstats.meta[cCode,c("noN")]<-T
}
```

## Add BETA column if missing
JZ moved this here so we can rely on BETA existing if either BETA or OR are present in the raw data file. We can't know if the effect is a non-OR unless we check though.
+++CH: Johan, what do you mean by "We can't know if the effect is a non-OR unless we check though."?
```{r add BETA column if missing}
# if no BETA column
if(any(colnames(cSumstats) == "BETA") == 0 & any(colnames(cSumstats) == "OR")){
    cSumstats$BETA<-log(cSumstats$OR) #calculate BETA from log of OR
    cat("BETA column inserted based on log OR value")
    sumstats.meta[cCode,c("Effect")]<-"OR"
} else if(any(colnames(cSumstats) == "BETA")) {
    cat("BETA column detected")
    sumstats.meta[cCode,c("Effect")]<-"BETA"
}
```



## Add missing Z column
We know that BETA exists if any effect provided previously
+++JZ: Need to be inferred from both the P and the sign of any existing effect. If the effect is not known we cannot know the direction of Z either just from P. Can be calculated from EFFECT and SE but the SE may not be reliable as it can be given on the ln scale or not. There are ways we can check this and maybe it should be part of the light cleaning as well.

```{r insert Z column if missing}
# if no Z column
if(any(colnames(cSumstats) == "Z") == 0 & any(colnames(cSumstats)=="BETA")){
  cSumstats$Z <- sign(cSumstats$BETA)*sqrt(qchisq(cSumstats$P,1,lower=F)) #calculate Z value using qchisq
  cat("Z column inserted based on P value and sign(BETA)")
  sumstats.meta[cCode,c("Z")]<-"P,sign(BETA)"
} else if(any(colnames(cSumstats)=="SE") & any(colnames(cSumstats)=="BETA")){
  cSumstats$Z <- cSumstats$BETA/cSumstats$SE
  cat("Z column inserted based on BETA value and SE")
  sumstats.meta[cCode,c("Z")]<-"BETA,SE"
}
```


## Add missing effect standard errors column 
If missing, add standard errors from beta & z (we always have BETA now if any effect provided previously)
```{r insert SE column if missing}
# if no SE column
if(any(colnames(cSumstats) == "SE") == 0){ 
  if(any(colnames(cSumstats) == "BETA") == 1){ #take BETA if BETA column exists
    cSumstats$SE<-abs(cSumstats$BETA/cSumstats$Z) #calculate SE from BETA and Z
  }
  cat("SE column inserted based on BETA/OR and P")
  sumstats.meta[cCode,c("SE")]<-"BETA,Z"
}
```


## Meta data about sufficient columns for analyses
Add information to metadata if there are enough columns for PRS and pathway analysis
```{r add meta data for PRS & pathway analysis}
sumstats.meta[cCode,c("enough_columns_PRS")] <- #sufficient columns for PRS analysis
  any(colnames(cSumstats)=="SNP") &
  any(colnames(cSumstats)=="P") &
  (any(colnames(cSumstats)=="BETA") |
     any(colnames(cSumstats)=="OR") |
     any(colnames(cSumstats)=="Z") ) &
  any(colnames(cSumstats)=="A1") &
  any(colnames(cSumstats)=="A2")

sumstats.meta[cCode,c("enough_columns_pathway_analysis")] <- #sufficient columns  for pathway analysis
  any(colnames(cSumstats)=="SNP") &
  any(colnames(cSumstats)=="P")

sumstats.meta
```


# Cleaning

##Missing data

Remove variants with missing P values and missing effect columns
Clean if missing P column
```{r clean missing p}
if(any(colnames(cSumstats)=="P")){
  cond <- is.na(cSumstats$P)
  sumstats.meta[cCode,c("n_removed_missing_p")]<-sum(cond)
  cSumstats<-cSumstats[which(!cond),]
}

sumstats.meta$n_removed_missing_p
```

Clean if missing effect columns 
```{r clean missing effect}
if(any(colnames(cSumstats)=="BETA")){ 
  cond <- is.na(cSumstats$BETA) #if NA for BETA value remove variant
  sumstats.meta[cCode,c("n_removed_missing_effect")]<-sum(cond)
  cSumstats<-cSumstats[which(!cond),]
} else if(any(colnames(cSumstats)=="OR")) {
  cond <- is.na(cSumstats$OR) #if NA for OR value remove variant
  sumstats.meta[cCode,c("n_removed_missing_effect")]<-sum(cond)
  cSumstats<-cSumstats[which(!cond),]
} else if(any(colnames(cSumstats)=="Z")) {
  cond <- is.na(cSumstats$Z) #if NA for Z value remove variant
  sumstats.meta[cCode,c("n_removed_missing_effect")]<-sum(cond)
  cSumstats<-cSumstats[which(!cond),]
}

sumstats.meta$n_removed_missing_effect
```


## Duplicate data

Deal with duplicate variants
```{r clean duplicate data}
# Remove duplicated variants across SNP, A1 and A2
if(any(colnames(cSumstats)=="SNP") & any(colnames(cSumstats)=="A1") & any(colnames(cSumstats)=="A2")) {
  cSumstats.n <- nrow(cSumstats)
  cSumstats <- unique(cSumstats,by = c("SNP","A1","A2"))
  sumstats.meta[cCode,c("n_removed_duplicates")]<-cSumstats.n-nrow(cSumstats)
}

sumstats.meta$n_removed_duplicates
```


## Value filters

?Remove variants based on MAF/FRQ, INFO, OR, p-value, N (Ollies script) filters etc

# Clean based on values

## P filter
```{r P filter}
if(any(colnames(cSumstats)=="P")){
  rm <- (!is.na(cSumstats$P) & (cSumstats$P>1 | cSumstats$P<0)) #if outside of bounds P < 0 or P > 1
  cSumstats <- cSumstats[!rm, ]
  cat("Removing ", sum(rm), " SNPs with P < 0 or P > 1; ", nrow(cSumstats), " remain") 
  sumstats.meta[cCode,c("n_removed_p")]<-sum(rm)
} else {
  cat("Warning: The dataset does not contain a P column to apply the specified filter on.")
}

sumstats.meta$n_removed_p
```

## FRQ filter
```{r FRQ filter}
if(any(colnames(cSumstats)=="FRQ")){
  rm <- (!is.na(cSumstats$FRQ) & (cSumstats$FRQ<0.005 | cSumstats$FRQ>0.995)) #if outside of bounds 
  cSumstats <- cSumstats[!rm, ]
  cat("Removing ", sum(rm), " SNPs with FRQ <", frq.filter, "; ", nrow(cSumstats), " remain")
  sumstats.meta[cCode,c("n_removed_frq")]<-sum(rm)
} else {
  cat("Warning: The dataset does not contain a FRQ or MAF column to apply the specified filter on.")
}

sumstats.meta$n_removed_frq
```


## INFO filter
```{r INFO filter}
if(any(colnames(cSumstats)=="INFO")){
  rm <- (!is.na(cSumstats$INFO) & cSumstats$INFO<0.6)
  cSumstats <- cSumstats[!rm, ]
  cat("Removing ", sum(rm), " SNPs with INFO < 0.6; ", nrow(cSumstats), " remain")
  sumstats.meta[cCode,c("n_removed_info")]<-sum(rm)
} else {
  cat("Warning: The dataset does not contain an INFO column to apply the specified filter on.")
}

sumstats.meta$n_removed_info
```

## OR filter
+++JZ: TODO - adapt to all kinds of effect types
```{r OR filter}
if(any(colnames(cSumstats)=="OR")){
  rm <- (!is.na(cSumstats$OR) & cSumstats$OR>10000)
  cSumstats <- cSumstats[!rm, ]
  cat("Removing ", sum(rm), " SNPs with OR > 10000; ", nrow(cSumstats), " remain")
  sumstats.meta[cCode,c("n_removed_or")]<-sum(rm)
} else {
  cat("Warning: The dataset does not contain an INFO column to apply the specified filter on.")
}

sumstats.meta$n_removed_or
```

## N filter - (from Ollies script)
+++ATK: do we want to remove SNPs that have a large N as set here? Or just SNPs with small N? 
```{r N filter}
if(any(colnames(cSumstats)=="N")){
  N_sd<-sd(cSumstats$N)
  N_median<-median(cSumstats$N)
  rm <- (!is.na(cSumstats$N) & (cSumstats$N > N_median+(3*N_sd) | cSumstats$N < N_median-(3*N_sd)))
  cSumstats <- cSumstats[!rm, ]
  cat("Removing ", sum(rm), " SNPs with N outside median(N) +- 3SD(N); ", nrow(cSumstats), " remain")
  sumstats.meta[cCode,c("n_removed_n")]<-sum(rm)
}

sumstats.meta$n_removed_n
```

# SE filter - from Ollies script
Note: if SE is 0 then this is flagged because it can cause issues in downstream analyses
```{r SE filter}
if(any(colnames(cSumstats)=="SE")){
  rm <- (!is.na(cSumstats$SE) & cSumstats$SE == 0) #if SE is 0 or NA - remove
  cSumstats <- cSumstats[!rm, ]
  cat("Removing ", sum(rm), " SNPs with SE = 0; ", nrow(cSumstats), " remain")
  sumstats.meta[cCode,c("n_removed_se")]<-sum(rm)
}

sumstats.meta$n_removed_se
```

#indels

+++Ollie: Preferable to not remove these as standard in light cleaning.

```{r indels filter}
if(keepIndel == F){ #if set at False, removes indels
  cSumstats$A1 <- as.character(cSumstats$A1, c("A", "C", "G", "T"))
  cSumstats$A2 <- as.character(cSumstats$A2, c("A", "C", "G", "T"))
  rm <- (is.na(cSumstats$A1) | is.na(cSumstats$A2))
  sumstats.meta[cCode,c("n_removed_indels")]<-sum(cond)
  cSumstats<-cSumstats[!rm,]
}

sumstats.meta$n_removed_indels
```


#Check and correct for Genomic Control

+++JZ Only relies on BETA as we know it exists if any effect provided previously
+++OP: This also relies on the SEs not being adjusted for genomic control, which does happen sometimes. Using the LDSC intercept might be a better approach for detection, although there is no easy way to reverse.

Added from Ollie's script:
```{r check and correct for genomic control}
if(any(colnames(cSumstats) == "SE") == 1){
  if(any(colnames(cSumstats) == "BETA") == 1){
    cSumstats$Z<-cSumstats$BETA/cSumstats$SE ####change to Z_check?
    cSumstats$P_check<-2*pnorm(-abs(cSumstats$Z))
    cSumstats$Z<-NULL

    if(abs(mean(cSumstats$P[!is.na(cSumstats$P_check)]) - mean(cSumstats$P_check[!is.na(cSumstats$P_check)])) > 0.01){
      cSumstats$P<-cSumstats$P_check
      cSumstats$P_check<-NULL
      
      cat("Genomic control detected. P-value recomputed using BETA and SE.")
      sumstats.meta[cCode,c("GC")]<-T
     
    } else {
     
      cat("Genomic control was not detected.")
      sumstats.meta[cCode,c("GC")]<-F
    
      cSumstats$P_check<-NULL
    }
    
  }
} else {
  
  cat("SE column is not present, genomic control cannot be detected.")
 
}


```
 
Need to add from Helenas (below):
Helena: /mnt/lustre/groups/ukbiobank/sumstats/scripts/computeLambdaAndCorrect.r
+++ OP: I have noticed gzfile sometimes truncates the output. the fwrite function now automatically gzips files if the file name ends with a 'gz'
```{r genomic control Helena's script}
##++++ATK: is there anything we want to add from Helena's below? http://genometoolbox.blogspot.com/2014/08/how-to-calculate-genomic-inflation.html
#arg <- commandArgs(TRUE)
#output <- arg[2]
#
#
#gres <- read.table(arg[1],header=T,sep="\t")
#
#chisq <- qchisq(1-gres$P,1) #check chisq
#
#lambda<-median(chisq)/qchisq(0.5,1) #check lambda
#
#gres$P <- pnorm(-abs((qnorm(gres$P/2)/sqrt(lambda))))*2 #check p 
#
#gres[,"N"]<-floor(gres[,"N"])
#
#gz1 <- gzfile(paste(output,".gz",sep=""),"w")
#write.table(gres,gz1,quote=F,row.names=F,col.names=T,sep="\t")
#close(gz1)
```

# GC calculation: Lambda
The block below relies on the Z value being up to date.
```{r Calculate lambda GC}
#http://genometoolbox.blogspot.com/2014/08/how-to-calculate-genomic-inflation.html

sumstats.meta[cCode,c("lambdaGC")] <- median(cSumstats$Z^2)/qchisq(0.5,1)

cat("\nThe genomic inflation factor (lambda GC) was calculated as: ",round(sumstats.meta[cCode,c("lambdaGC")],digits = 2))

```

#Harmonise with the reference

To insert and/or check reference MAFs, the user must assign appropriate super population for GWAS. If missing or mixed, no reference MAF should be inserted.

This step will also insert RSIDs where possible.

No variants will be removed from the GWAS during this haronisation step to retain information for downstream analyses that do not require the variants to be in the reference.

INDELS are reported in such a varied way across GWAS, that we will only harmonise SNPs.

We will also only insert MAF for non-ambiguous SNPs.

```{r}
# Insert IUPAC codes into target
cSumstats$IUPAC[cSumstats$A1 == 'A' & cSumstats$A2 =='T' | cSumstats$A1 == 'T' & cSumstats$A2 =='A']<-'W'
cSumstats$IUPAC[cSumstats$A1 == 'C' & cSumstats$A2 =='G' | cSumstats$A1 == 'G' & cSumstats$A2 =='C']<-'S'
cSumstats$IUPAC[cSumstats$A1 == 'A' & cSumstats$A2 =='G' | cSumstats$A1 == 'G' & cSumstats$A2 =='A']<-'R'
cSumstats$IUPAC[cSumstats$A1 == 'C' & cSumstats$A2 =='T' | cSumstats$A1 == 'T' & cSumstats$A2 =='C']<-'Y'
cSumstats$IUPAC[cSumstats$A1 == 'G' & cSumstats$A2 =='T' | cSumstats$A1 == 'T' & cSumstats$A2 =='G']<-'K'
cSumstats$IUPAC[cSumstats$A1 == 'A' & cSumstats$A2 =='C' | cSumstats$A1 == 'C' & cSumstats$A2 =='A']<-'M'

# Define super population
super_pop<-'EUR' # Should be specified by user

###########
# Merge with the reference
###########
# Initially target should be merged with the reference based on CHR, BP and IUPAC. RSIDs will be inserted for all SNPs, and reference MAF will be inserted for all non-ambiguous SNPs if the super population is specified.
# If CHR and BP are unavailable, but RSID is present, target will be merged with the reference by RSID and IUPAC. CHR and BP will be inserted for all SNPs, and reference MAF will be inserted for all non-ambiguous SNPs if the super population is specified.

# Check whether RSIDs are available for majority of SNPs in GWAS
chr_bp_avail<-sum(c('CHR','ORIGBP') %in% names(cSumstats)) == 2 
rsid_avail<-(sum(grepl('rs', cSumstats$SNP)) > 0.9*length(cSumstats$SNP))

if(chr_bp_avail){
  ###
  # Determine build
  ###
  # Read in chromosome 22 of reference data
  i<-22
  ref<-list()

  ref[['GRCh37']]<-fread(paste0('/scratch/groups/biomarkers-brc-mh/Reference_data/1KG_Phase3/PLINK/all_phase3.chr',i,'.bim'))
  ref[['GRCh37']]$V3<-NULL
  names(ref[['GRCh37']])<-c('chr','snp','pos','a1','a2')
  
  # Update BP from build GRCh37 (hg19) to GRCh38
  # Create snp_modifyBuild_offline
  make_executable <- function(exe) {
    Sys.chmod(exe, mode = (file.info(exe)$mode | "111"))
  }
  
  snp_modifyBuild_offline<-function (info_snp, liftOver, chain, from = "hg18", to = "hg19"){
    if (!all(c("chr", "pos") %in% names(info_snp)))
      stop2("Please use proper names for variables in 'info_snp'. Expected %s.",
            "'chr' and 'pos'")
    liftOver <- normalizePath(liftOver)
    make_executable(liftOver)
    BED <- tempfile(fileext = ".BED")
    info_BED <- with(info_snp, data.frame(paste0("chr", chr),
                                          pos0 = pos - 1L, pos, id = seq_len(nrow(info_snp))))
    bigreadr::fwrite2(info_BED, BED, col.names = FALSE, sep = " ")
    lifted<-'/users/k1806347/tmp/tmp.lifted'
    unmapped<-'/users/k1806347/tmp/tmp.unmapped'
    system(paste(liftOver, BED, chain, lifted, unmapped))
    new_pos <- bigreadr::fread2(lifted)
    bad <- grep("^#", readLines(unmapped), value = TRUE, invert = TRUE)
    print(paste0(length(bad)," variants have not been mapped."))
    info_snp$pos <- NA
    info_snp$pos[new_pos$V4] <- new_pos$V3
    info_snp
  }

  # Liftover BP to GRCh38
  ref[['GRCh38']]<-snp_modifyBuild_offline(ref[['GRCh37']], liftOver='/users/k1806347/brc_scratch/Software/MyGit/GenoPred/GenoPredPipe/resources/software/liftover/liftover', chain='/users/k1806347/brc_scratch/Software/MyGit/GenoPred/GenoPredPipe/resources/data/liftover/hg18ToHg19.over.chain.gz', from = "hg18", to = "hg19")

  names(ref[['GRCh37']])<-c('CHR','SNP','BP','A1','A2')
  names(ref[['GRCh38']])<-c('CHR','SNP','BP','A1','A2')

  # Insert IUPAC codes in ref (GRCh38)
  ref[['GRCh38']]$IUPAC[ref[['GRCh38']]$A1 == 'A' & ref[['GRCh38']]$A2 =='T' | ref[['GRCh38']]$A1 == 'T' & ref[['GRCh38']]$A2 =='A']<-'W'
  ref[['GRCh38']]$IUPAC[ref[['GRCh38']]$A1 == 'C' & ref[['GRCh38']]$A2 =='G' | ref[['GRCh38']]$A1 == 'G' & ref[['GRCh38']]$A2 =='C']<-'S'
  ref[['GRCh38']]$IUPAC[ref[['GRCh38']]$A1 == 'A' & ref[['GRCh38']]$A2 =='G' | ref[['GRCh38']]$A1 == 'G' & ref[['GRCh38']]$A2 =='A']<-'R'
  ref[['GRCh38']]$IUPAC[ref[['GRCh38']]$A1 == 'C' & ref[['GRCh38']]$A2 =='T' | ref[['GRCh38']]$A1 == 'T' & ref[['GRCh38']]$A2 =='C']<-'Y'
  ref[['GRCh38']]$IUPAC[ref[['GRCh38']]$A1 == 'G' & ref[['GRCh38']]$A2 =='T' | ref[['GRCh38']]$A1 == 'T' & ref[['GRCh38']]$A2 =='G']<-'K'
  ref[['GRCh38']]$IUPAC[ref[['GRCh38']]$A1 == 'A' & ref[['GRCh38']]$A2 =='C' | ref[['GRCh38']]$A1 == 'C' & ref[['GRCh38']]$A2 =='A']<-'M'
  
  # Insert IUPAC codes in ref (ref[['GRCh37']])
  ref[['GRCh37']]$IUPAC[ref[['GRCh37']]$A1 == 'A' & ref[['GRCh37']]$A2 =='T' | ref[['GRCh37']]$A1 == 'T' & ref[['GRCh37']]$A2 =='A']<-'W'
  ref[['GRCh37']]$IUPAC[ref[['GRCh37']]$A1 == 'C' & ref[['GRCh37']]$A2 =='G' | ref[['GRCh37']]$A1 == 'G' & ref[['GRCh37']]$A2 =='C']<-'S'
  ref[['GRCh37']]$IUPAC[ref[['GRCh37']]$A1 == 'A' & ref[['GRCh37']]$A2 =='G' | ref[['GRCh37']]$A1 == 'G' & ref[['GRCh37']]$A2 =='A']<-'R'
  ref[['GRCh37']]$IUPAC[ref[['GRCh37']]$A1 == 'C' & ref[['GRCh37']]$A2 =='T' | ref[['GRCh37']]$A1 == 'T' & ref[['GRCh37']]$A2 =='C']<-'Y'
  ref[['GRCh37']]$IUPAC[ref[['GRCh37']]$A1 == 'G' & ref[['GRCh37']]$A2 =='T' | ref[['GRCh37']]$A1 == 'T' & ref[['GRCh37']]$A2 =='G']<-'K'
  ref[['GRCh37']]$IUPAC[ref[['GRCh37']]$A1 == 'A' & ref[['GRCh37']]$A2 =='C' | ref[['GRCh37']]$A1 == 'C' & ref[['GRCh37']]$A2 =='A']<-'M'
  
  # Check target-ref condordance of BP across builds
  ref[['GRCh37']]$CHR<-as.character(ref[['GRCh37']]$CHR)
  ref[['GRCh38']]$CHR<-as.character(ref[['GRCh38']]$CHR)
  matched<-list()
  matched[['GRCh37']]<-merge(cSumstats, ref[['GRCh37']], by.x=c('CHR','ORIGBP','IUPAC'), by.y=c('CHR','BP','IUPAC'))
  matched[['GRCh38']]<-merge(cSumstats, ref[['GRCh38']], by.x=c('CHR','ORIGBP','IUPAC'), by.y=c('CHR','BP','IUPAC'))
  
  cat('GRCh37 match: ',round(nrow(matched[['GRCh37']])/sum(cSumstats$CHR == i)*100, 2),'%\n',sep='')
  cat('GRCh38 match: ',round(nrow(matched[['GRCh38']])/sum(cSumstats$CHR == i)*100, 2),'%\n',sep='')

  target_build<-NA
  if((nrow(matched[['GRCh37']])/sum(cSumstats$CHR == i)) > 0.7 & (nrow(matched[['GRCh37']])/sum(cSumstats$CHR == i)) > (nrow(matched[['GRCh38']])/sum(cSumstats$CHR == i))){
    target_build<-'GRCh37'
  }
  
  if((nrow(matched[['GRCh38']])/sum(cSumstats$CHR == i)) > 0.7 & (nrow(matched[['GRCh38']])/sum(cSumstats$CHR == i)) > (nrow(matched[['GRCh37']])/sum(cSumstats$CHR == i))){
    target_build<-'GRCh38'
  }
  
  if(!is.na(target_build)){
    # Build detected, so can continue reference harmonisation
    # Run per chromosome to reduce memory requirements
    chrs<-unique(cSumstats$CHR)

    cSumstats_matched<-NULL
    cSumstats_unmatched<-NULL
    for(i in chrs){
      print(i)
      
      # Read reference data
      tmp<-fread(paste0('/scratch/groups/biomarkers-brc-mh/Reference_data/1KG_Phase3/PLINK/all_phase3.chr',i,'.bim'))
      tmp<-tmp[nchar(tmp$V5) == 1 & nchar(tmp$V6) == 1,]
      names(tmp)<-c('CHR','SNP','POS','BP','A1','A2')
      tmp$POS<-NULL
      tmp$CHR<-NULL
      
      # Insert IUPAC codes into ref
      tmp$IUPAC[tmp$A1 == 'A' & tmp$A2 =='T' | tmp$A1 == 'T' & tmp$A2 =='A']<-'W'
      tmp$IUPAC[tmp$A1 == 'C' & tmp$A2 =='G' | tmp$A1 == 'G' & tmp$A2 =='C']<-'S'
      tmp$IUPAC[tmp$A1 == 'A' & tmp$A2 =='G' | tmp$A1 == 'G' & tmp$A2 =='A']<-'R'
      tmp$IUPAC[tmp$A1 == 'C' & tmp$A2 =='T' | tmp$A1 == 'T' & tmp$A2 =='C']<-'Y'
      tmp$IUPAC[tmp$A1 == 'G' & tmp$A2 =='T' | tmp$A1 == 'T' & tmp$A2 =='G']<-'K'
      tmp$IUPAC[tmp$A1 == 'A' & tmp$A2 =='C' | tmp$A1 == 'C' & tmp$A2 =='A']<-'M'
      
      # Read in reference frequency data
      freq<-fread(paste0('/scratch/groups/biomarkers-brc-mh/Reference_data/1KG_Phase3/PLINK/MAF/',super_pop,'/all_phase3.',super_pop,'.chr',i,'.frq'))
      
      # The freq files have come from the reference files, so we can assume they are on the same strand
      freq_match<-merge(tmp, freq[,c('SNP','A1','A2','MAF'), with=F], by=c('SNP','A1','A2'))
      freq_swap<-merge(tmp, freq[,c('SNP','A1','A2','MAF'), with=F], by.x=c('SNP','A1','A2'), by.y=c('SNP','A2','A1'))
      freq_swap$MAF<-1-freq_swap$MAF
      tmp<-rbind(freq_match, freq_swap)
      
      names(tmp)[names(tmp) == 'SNP']<-'REF.SNP'
      names(tmp)[names(tmp) == 'MAF']<-'REF.FRQ'
      names(tmp)[names(tmp) == 'BP']<-'REF.BP'

      # Merge target and reference by BP
      cSumstats_chr<-cSumstats[cSumstats$CHR == i,]
      ref_target<-merge(cSumstats_chr, tmp, by.x=c('ORIGBP'), by.y=c('REF.BP'))
      
      # Identify SNPs that have matched alleles
      matched<-ref_target[ref_target$IUPAC.x == ref_target$IUPAC.y,]
  
      # Remove REF.FRQ for ambiguous SNPs
      matched$REF.FRQ[matched$IUPAC.x %in% c('w','S')]<-NA
      
      # For ambiguous SNPs, set ref A1 and A2 as target A1 and A2
      matched$A1.y[matched$IUPAC.x %in% c('w','S')]<-matched$A1.x[matched$IUPAC.x %in% c('w','S')]
      matched$A2.y[matched$IUPAC.x %in% c('w','S')]<-matched$A2.x[matched$IUPAC.x %in% c('w','S')]
      
      # Identify SNPs that are opposite strands
      flipped<-ref_target[(ref_target$IUPAC.x == 'R' & ref_target$IUPAC.y == 'Y') | 
                          (ref_target$IUPAC.x == 'Y' & ref_target$IUPAC.y == 'R') | 
                          (ref_target$IUPAC.x == 'K' & ref_target$IUPAC.y == 'M') |
                          (ref_target$IUPAC.x == 'M' & ref_target$IUPAC.y == 'K'),]
      
      # For strand flipped variants, change to match reference
      if('FRQ' %in% names(cSumstats)){
        flipped$FRQ<-1-flipped$FRQ
      }
      if('BETA' %in% names(cSumstats)){
        flipped$BETA<--flipped$BETA
      }
      if('OR' %in% names(cSumstats)){
        flipped$OR<-exp(-log(flipped$OR))
      }
      
      # Retain reference CHR, BP, A1, and A2 information
      matched_flipped<-rbind(matched, flipped)
      matched_flipped$A1<-matched_flipped$A1.y
      matched_flipped$A1.y<-NULL
      matched_flipped$A1.x<-NULL
      matched_flipped$A2<-matched_flipped$A2.y
      matched_flipped$A2.y<-NULL
      matched_flipped$A2.x<-NULL
      matched_flipped$IUPAC<-matched_flipped$IUPAC.y
      matched_flipped$IUPAC.y<-NULL
      matched_flipped$REF.CHR<-matched_flipped$CHR
      matched_flipped$REF.BP<-matched_flipped$ORIGBP

      # Idntify SNPs that are unmatched
      unmatched_chr<-cSumstats_chr[!(paste0(cSumstats_chr$ORIGBP,':',cSumstats_chr$IUPAC) %in% paste0(matched_flipped$ORIGBP,':',matched_flipped$IUPAC.x)),]
      matched_flipped$IUPAC.x<-NULL

      cSumstats_matched<-rbind(cSumstats_matched, matched_flipped)
      cSumstats_unmatched<-rbind(cSumstats_unmatched, unmatched_chr)
    }
    
    # Reinsert variants in GWAS that could not be matched to the reference
    # These unmatched variants include those with CHR:BP:IUPAC not in the reference, and INDELS.
    cSumstats_unmatched$REF.CHR<-NA
    cSumstats_unmatched$REF.BP<-NA
    cSumstats_unmatched$REF.SNP<-NA
    cSumstats_unmatched$REF.FRQ<-NA

    cSumstats_harm<-rbind(cSumstats_matched, cSumstats_unmatched)
  }
} else {
  if(rsid_avail = T){
    # Run per chromosome to reduce memory requirements
    chrs<-c(1:22,'X','Y','MT')
  
    cSumstats_matched<-NULL
    for(i in chrs){
      print(i)
      
      # Read reference data
      tmp<-fread(paste0('/scratch/groups/biomarkers-brc-mh/Reference_data/1KG_Phase3/PLINK/all_phase3.chr',i,'.bim'))
      tmp<-tmp[nchar(tmp$V5) == 1 & nchar(tmp$V6) == 1,]
      names(tmp)<-c('CHR','SNP','POS','BP','A1','A2')
      tmp$POS<-NULL
      
      # Insert IUPAC codes into ref
      tmp$IUPAC[tmp$A1 == 'A' & tmp$A2 =='T' | tmp$A1 == 'T' & tmp$A2 =='A']<-'W'
      tmp$IUPAC[tmp$A1 == 'C' & tmp$A2 =='G' | tmp$A1 == 'G' & tmp$A2 =='C']<-'S'
      tmp$IUPAC[tmp$A1 == 'A' & tmp$A2 =='G' | tmp$A1 == 'G' & tmp$A2 =='A']<-'R'
      tmp$IUPAC[tmp$A1 == 'C' & tmp$A2 =='T' | tmp$A1 == 'T' & tmp$A2 =='C']<-'Y'
      tmp$IUPAC[tmp$A1 == 'G' & tmp$A2 =='T' | tmp$A1 == 'T' & tmp$A2 =='G']<-'K'
      tmp$IUPAC[tmp$A1 == 'A' & tmp$A2 =='C' | tmp$A1 == 'C' & tmp$A2 =='A']<-'M'
      
      # Read in reference frequency data
      freq<-fread(paste0('/scratch/groups/biomarkers-brc-mh/Reference_data/1KG_Phase3/PLINK/MAF/',super_pop,'/all_phase3.EUR.chr',i,'.frq'))
      
      # The freq files have come from the reference files, so we can assume they are on the same strand
      freq_match<-merge(tmp, freq[,c('SNP','A1','A2','MAF'), with=F], by=c('SNP','A1','A2'))
      freq_swap<-merge(tmp, freq[,c('SNP','A1','A2','MAF'), with=F], by.x=c('SNP','A1','A2'), by.y=c('SNP','A2','A1'))
      freq_swap$MAF<-1-freq_swap$MAF
      tmp<-rbind(freq_match, freq_swap)
      
      names(tmp)[names(tmp) == 'MAF']<-'REF.FRQ'
      names(tmp)[names(tmp) == 'BP']<-'REF.BP'
      names(tmp)[names(tmp) == 'CHR']<-'REF.CHR'
      
      # Merge target and reference by SNP ID
      ref_target<-merge(cSumstats, tmp, by='SNP')
      
      # Identify SNPs that have matched alleles
      matched<-ref_target[ref_target$IUPAC.x == ref_target$IUPAC.y,]
  
      # Remove REF.FRQ for ambiguous SNPs
      matched$REF.FRQ[matched$IUPAC.x %in% c('w','S')]<-NA
      
      # For ambiguous SNPs, set ref A1 and A2 as target A1 and A2
      matched$A1.y[matched$IUPAC.x %in% c('w','S')]<-matched$A1.x[matched$IUPAC.x %in% c('w','S')]
      matched$A2.y[matched$IUPAC.x %in% c('w','S')]<-matched$A2.x[matched$IUPAC.x %in% c('w','S')]
  
      # Identify SNPs that are opposite strands
      flipped<-ref_target[(ref_target$IUPAC.x == 'R' & ref_target$IUPAC.y == 'Y') | 
                          (ref_target$IUPAC.x == 'Y' & ref_target$IUPAC.y == 'R') | 
                          (ref_target$IUPAC.x == 'K' & ref_target$IUPAC.y == 'M') |
                          (ref_target$IUPAC.x == 'M' & ref_target$IUPAC.y == 'K'),]
      
      # For strand flipped variants, change to match reference
      if('FRQ' %in% names(cSumstats)){
        flipped$FRQ<-1-flipped$FRQ
      }
      if('BETA' %in% names(cSumstats)){
        flipped$BETA<--flipped$BETA
      }
      if('OR' %in% names(cSumstats)){
        flipped$OR<-exp(-log(flipped$OR))
      }
      
      # Retain reference CHR, BP, A1, and A2 information
      matched_flipped<-rbind(matched, flipped)
      matched_flipped$A1<-matched_flipped$A1.y
      matched_flipped$A1.y<-NULL
      matched_flipped$A1.x<-NULL
      matched_flipped$A2<-matched_flipped$A2.y
      matched_flipped$A2.y<-NULL
      matched_flipped$A2.x<-NULL
      matched_flipped$IUPAC<-matched_flipped$IUPAC.y
      matched_flipped$IUPAC.y<-NULL
      matched_flipped$IUPAC.x<-NULL
      matched_flipped$REF.SNP<-matched_flipped$SNP
  
      cSumstats_matched_chr<-rbind(matched_flipped)
      cSumstats_matched<-rbind(cSumstats_matched, cSumstats_matched_chr)
    }
    
    # Idntify SNPs that are unmatched
    unmatched<-cSumstats[!(cSumstats$SNP %in% cSumstats_matched$SNP),]
    
    # Reinsert variants in GWAS that could not be matched to the reference
    # These unmatched variants include those with RSIDs not in the reference, any ambiguous SNPs, and INDELS.
    unmatched$REF.SNP<-NA
    unmatched$REF.FRQ<-NA
    unmatched$REF.CHR<-NA
    unmatched$REF.BP<-NA
  
    cSumstats_harm<-rbind(cSumstats_matched, unmatched)

  }
}

```

#Deal with maf and frequencey columns

NOTE: This would only work if in the harmonization step earlier, the MAF_REF column was insterted into the cSumstats dataframe (so need to add harmonisation step before this step)

+++Alish: this is slightly different to what we were previously doing in Helena's script. Discuss in meeting?
+++OP: I notice this FRQ check isn't functional yet. Are alleles flipped?

#Compares to reference and inverts MAFs if they are incorrect based on average allele frequency.
```{r allele Frequency columns and MAF inversion}
# Check FRQ column is valid
if(any(cSumstats$FRQ>1) || any(cSumstats$FRQ<0)) {
      
      stop(paste0('\nThere are FRQ values larger than 1 (',sum(cSumstats$FRQ>1),') or less than 0 (',sum(cSumstats$FRQ<0),') which is outside of the possible FRQ range.')
      )
    }

### Invert FRQ based on the previous reference matching
  if(!is.null(cond.invertedAlleleOrder) & !harmoniseAllelesToReference) {
    
    alleleFRQ <- ifelse(cond.invertedAlleleOrder, (1-cSumstats$FRQ), cSumstats$FRQ)
    
    if(mean(alleleFRQ)<mean(cSumstats$FRQ)){
      
      cSumstats$FRQ<-alleleFRQ
      
      cSumstats.meta<-rbind(cSumstats.meta,list("FRQ","Fitted (flipped) according to reference allele order"))
      
      sumstats.meta[iFile,c("FRQ.flipped")] <- T
      
      } else {
        
        cond.invertedMAF<-cSumstats$FRQ > .5
        
        cSumstats$FRQ<-ifelse(cond.invertedMAF,1-cSumstats$FRQ,cSumstats$FRQ)
        
        cSumstats.meta<-rbind(cSumstats.meta,list("FRQ","Set to MAF"))
        
        sumstats.meta[iFile,c("FRQ.flipped")]<-F
        
      }
  }
```

#if allele frequency column is missing, infer from reference panel 

```{r Compute MAF columns based on reference MAF}
### Compute MAF 

  if(cond.invertedMAF<-cSumstats$FRQ > .5){
    
    cSumstats$MAF<-ifelse(cond.invertedMAF,1-cSumstats$FRQ,cSumstats$FRQ)
  
  ### Does not have FRQ
  #### Note that FRQ is not present
  
  if(sumstats.meta[iFile,c("no_FRQ")]<-T){
    
  cSumstats.warnings<-c(cSumstats.warnings,"No FRQ column present!")
  
  }
  
  if(!is.null(ref)){
    
    #Set FRQ from ref if not present
    
    cSumstats$FRQ <- cSumstats$MAF_REF #creates new column with allele frequency inffered from reference
    
    cSumstats.warnings <- c(cSumstats.warnings,"Inferring FRQ from reference!")
    
  }
    
  else {
      
    #### Add empty FRQ here for consistency (sets to NAs)
    
      cSumstats$FRQ<-NA_real_
      
  }
  }

```


# Save cleaned file and log output

+++JZ: When converted to a function we would want to provide this as an argument (with the possibility of a default value).
```{r save cleaned file as .gz file in cleaned folder}
cSumstats %>%
  gzfile(
    file = paste0("../cleaned/", cCode, ".gz", sep="\t"))

```

# Update overview spreadsheet

+++JZ: TODO
```{r update overview metadata spreadsheet}



```


+++CH: Additionally, a log file should be created and be saved in the log file folder
```{r create log file and save in log file folder}

```

?Read in reference from plink formats
```{r read in reference}

```


## MHC removal (separate from cleaning script)
This should happen after the LDSC munging; some people will want to use the MHC variants for their analyses

remove MHC region based on position - probably better to do after merge/harmonisation with reference
references:
https://www.ncbi.nlm.nih.gov/grc/human/regions/MHC?asm=GRCh37
https://www.ncbi.nlm.nih.gov/grc/human/regions/MHC
```{r MHC removal}
if(!is.na(mhc.filter)){
  if(any(colnames(cSumstats)=="CHR") & any(colnames(cSumstats)=="BP")){
    if(mhc.filter==37) {
        rm <- (!is.na(cSumstats$CHR) & !is.na(cSumstats$BP) & cSumstats$CHR=="6" & cSumstats$BP>=28477797 & cSumstats$BP<=33448354)
        cSumstats <- cSumstats[!rm, ]
    } else if (mhc.filter==38) {
        rm <- (!is.na(cSumstats$CHR) & !is.na(cSumstats$BP) & cSumstats$CHR=="6" & cSumstats$BP>=28510120 & cSumstats$BP<=33480577)
        cSumstats <- cSumstats[!rm, ]
        cat("Removing ", sum(rm), " SNPs in the GRCh",mhc.filter," MHC; ", nrow(cSumstats), " remain")
    } else {
        cat("Warning: Invalid assembly version provided - no filtering of the MHC was done!")
      }
  } else {
    cat("Warning: No chromosome or base-pair position information available - no filtering of the MHC was done!")
  }
}
```

#Munge sumstats
```{r}

#Write the trait code into a text file 
c(traitCodes) %>% write_lines( "GWAS_name.txt")

```

```{bash}
#!/bin/bash
#SBATCH -n 8
#SBATCH --mem-per-cpu=9G
#SBATCH -t 72:00:00

###
module add devtools/anaconda/2019.3-python2.7.16

#parameters
input_path="/scratch/groups/ukbiobank/sumstats/cleaned/"
file=`cat GWAS_name.txt`
output_path="/scratch/groups/ukbiobank/sumstats/munged/"
ldscdir="/scratch/groups/ukbiobank/Edinburgh_Data/Software/ldscore/"
#optional parameters to compute h2 liability scale
#Nca=$3
#Nco=$4

#####munge with w_hm3
python ${ldscdir}/munge_sumstats.py --out ${output_path}/${file} --merge-alleles ${ldscdir}/w_hm3.snplist --N-cas-col Ncas --N-con-col Ncon --N-col N --sumstats /scratch/groups/ukbiobank/sumstats/cleaned/${input_path}/${file}.gz --info-min 0.6

```


#Supermunge
```{r Supermunge}
if(doSupermunge){
  supermungeTraitCode<-paste0(traitCodes[1],"_supermunge")
  supermunge(
    list_df = list(cSumstats),
    refFilePath = "/scratch/groups/ukbiobank/Edinburgh_Data/Software/ldscore/w_hm3.snplist",
    traitNames = paste0(traitCodes[1],"_supermunge"),
    pathDirOutput = "/scratch/groups/ukbiobank/sumstats/munged/",
    N = cN,
    keepIndel = keepIndel
      )
  
  Sys.setenv(supermunge_trait_code=supermungeTraitCode)
}
```


#LD score
```{bash}
#!/bin/bash
#SBATCH -n 8
#SBATCH --mem-per-cpu=9G
#SBATCH -t 72:00:00

###
module add devtools/anaconda/2019.3-python2.7.16

#parameters
input_path="/scratch/groups/ukbiobank/sumstats/cleaned/"
file=`cat GWAS_name.txt`
output_path="/scratch/groups/ukbiobank/sumstats/munged/"
ldscdir="/scratch/groups/ukbiobank/KCL_Data/Software/ldsc/"

#run ldsc 
python ${ldscdir}/ldsc.py --h2 ${output_path}/${file}.gz --ref-ld-chr ${ldscdir}/eur_w_ld_chr/ --w-ld-chr ${ldscdir}/eur_w_ld_chr/ --out ${output_path}/${file}_herit

```

#LD score 2
```{bash}
#!/bin/bash
#SBATCH -n 8
#SBATCH --mem-per-cpu=9G
#SBATCH -t 72:00:00
if [[ -v supermunge_trait_code ]]; then
###
module add devtools/anaconda/2019.3-python2.7.16

#parameters
input_path="/scratch/groups/ukbiobank/sumstats/cleaned/"
output_path="/scratch/groups/ukbiobank/sumstats/munged/"
ldscdir="/scratch/groups/ukbiobank/KCL_Data/Software/ldsc/"

#run ldsc 
python ${ldscdir}/ldsc.py --h2 ${output_path}/${supermunge_trait_code}.gz --ref-ld-chr ${ldscdir}/eur_w_ld_chr/ --w-ld-chr ${ldscdir}/eur_w_ld_chr/ --out ${output_path}/${supermunge_trait_code}_herit

fi

```



