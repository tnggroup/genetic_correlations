---
title: "rg results summary tables template"
author: "Abigail ter Kuile"
date: "28/08/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      comment=NA,
                      prompt=FALSE,
                      cache=FALSE)
```

Clear global environment
```{r Clear global environment}
remove(list = ls())
```

# Package setup
```{r Packages}
library(optparse)
library(data.table)
library(summarytools)
library(tidyverse)
```


```{r command line setup}
clParser <- OptionParser()
clParser <- add_option(clParser, c("-t", "--task"), type="character", default="clean",
                help="The explicit task to run:\nclean: Clean GWAS sumstat [default %default]")
clParser <- add_option(clParser, c("-f", "--file"), type="character",
                help="The file to process")
clParser <- add_option(clParser, c("-c", "--code"), type="character",
                help="The code to use for the dataset from the specified file.")
clParser <- add_option(clParser, c("-n", "--sample-size"), type="numeric",
                help="Number of individuals in the sample.")

clOptions<-parse_args(clParser)

```

# Script settings
```{r Script setting}

filename.rmd<-"sumstats_cleaning.Rmd"

#explicitly set total N
cN <- clOptions$`sample-size`
#setting for keeping or removing indels
keepIndel<-F


```

# R script export
```{r Purl export, include=FALSE, purl=FALSE, eval=FALSE}
#running this will produce an R-script with the same name as the Rmd-file.
knitr::purl(filename.rmd)
  
```

Retrieve the recent date
```{r Recent date}
date = Sys.Date()
date
```
# Functions to be used later
```{r functions}

stdGwasColumnNames <- function(columnNames, stopOnMissingEssential=T,
     c.SNP = c("SNP","PREDICTOR","SNPID","MARKERNAME","MARKER_NAME","SNPTESTID","ID_DBSNP49","RSID","ID","RS_NUMBER","MARKER", "RS", "RSNUMBER", "RS_NUMBERS", "SNP.NAME","SNP ID", "SNP_ID","LOCATIONALID","ASSAY_NAME"),
     c.A1 = c("A1","ALLELE1","ALLELE_1","INC_ALLELE","EA","A1_EFFECT","REF","EFFECT_ALLELE","RISK_ALLELE","EFFECTALLELE","EFFECT_ALL","REFERENCE_ALLELE","REF_ALLELE","REFERENCEALLELE","EA","ALLELE_1","INC_ALLELE","ALLELE1","A","A_1","CODED_ALLELE","TESTED_ALLELE"),
     c.A2 = c("A2","ALLELE2","ALLELE_2","OTHER_ALLELE","NON_EFFECT_ALLELE","DEC_ALLELE","OA","NEA","ALT","A2_OTHER","NONREF_ALLELE","NEFFECT_ALLELE","NEFFECTALLELE","NONEFFECT_ALLELE","OTHER_ALL","OTHERALLELE","NONEFFECTALLELE","ALLELE0","ALLELE_0","ALT_ALLELE","A_0","NONCODED_ALLELE"),
     #c.EFFECT = c("EFFECT","OR","B","BETA","LOG_ODDS","EFFECTS","SIGNED_SUMSTAT","EST"),
     c.BETA = c("BETA","B","EFFECT_BETA","EFFECT","EFFECTS","SIGNED_SUMSTAT","EST","GWAS_BETA","EFFECT_A1","EFFECTA1","EFFECT_NW"),
     c.OR = c("OR","LOG_ODDS","OR","ODDS-RATIO","ODDS_RATIO","ODDSRATIO","OR(MINALLELE)","OR.LOGISTIC","OR_RAN","OR(A1)"),
     c.SE = c("SE","STDER","STDERR","STD","STANDARD_ERROR","OR_SE","STANDARDERROR", "STDERR_NW","META.SE","SE_DGC","SE.2GC"),
     c.Z = c("Z","ZSCORE","Z-SCORE","ZSTAT","ZSTATISTIC","GC_ZSCORE","BETAZSCALE"),
     c.INFO = c("INFO","IMPINFO","IMPQUALITY", "INFO.PLINK", "INFO_UKBB"),
     c.P = c("P","PVALUE","PVAL","P_VALUE","GC_PVALUE","WALD_P","P.VAL","GWAS_P","P-VALUE","P-VAL","FREQUENTIST_ADD_PVALUE","P.VALUE","P_VAL","SCAN-P","P.LMM","META.PVAL","P_RAN","P.ADD","P_BOLT_LMM"),
     c.N = c("N","WEIGHT","NCOMPLETESAMPLES","TOTALSAMPLESIZE","TOTALN","TOTAL_N","N_COMPLETE_SAMPLES","N_TOTAL","N_SAMPLES","N_ANALYZED","NSAMPLES","SAMPLESIZE","SAMPLE_SIZE","TOTAL_SAMPLE_SIZE","TOTALSAMPLESIZE"),
     c.N_CAS = c("N_CAS","NCASE","N_CASE","N_CASES","NCAS","NCA","NCASES","CASES","CASES_N","FRQ_A"),
     c.N_CON = c("N_CON","NCONTROL","N_CONTROL","N_CONTROLS","NCON","NCO","N_CON","NCONTROLS","CONTROLS","CONTROLS_N","FRQ_U"),
     c.NEF = c("NEF","NEFF","NEFFECTIVE","NE"),
     #include FRQ_A?
     c.FRQ = c("FRQ","MAF","AF","CEUAF","FREQ","FREQ1","EAF","FREQ1.HAPMAP","FREQALLELE1HAPMAPCEU", "FREQ.ALLELE1.HAPMAPCEU","EFFECT_ALLELE_FREQ","FREQ.A1","F_A","F_U","FREQ_A","FREQ_U","MA_FREQ","MAF_NW","FREQ_A1","A1FREQ","CODED_ALLELE_FREQUENCY","FREQ_TESTED_ALLELE_IN_HRS","EAF_HRC"),
     c.CHR = c("CHR","CH","CHROMOSOME","CHROM","CHR_BUILD38","CHR_BUILD37","CHR_BUILD36","CHR_B38","CHR_B37","CHR_B36","CHR_ID","SCAFFOLD","HG19CHR","CHR.HG19","CHR_HG19","HG18CHR","CHR.HG18","CHR_HG18","CHR_BP_HG19B37","HG19CHRC"),
     c.BP = c("BP","ORIGBP","POS","POSITION","LOCATION","PHYSPOS","GENPOS","CHR_POSITION","POS_B38","POS_BUILD38","POS_B37","POS_BUILD37","BP_HG19B37","POS_B36","POS_BUILD36","POS.HG19","POS.HG18","POS_HG19","POS_HG18","BP_HG19","BP_HG18","BP.GRCH38","BP.GRCH37","POSITION(HG19)","POSITION(HG18)","POS(B38)","POS(B37)")
                                       ){
  #test
  #columnNames<-cSumstats.names
  
  columnNames.upper<-toupper(columnNames)
  #names(columnNames)<-columnNames
  columnNames.orig<-columnNames
  
  columnNames[columnNames.upper %in% c.SNP] <- c.SNP[1]
  columnNames[columnNames.upper %in% c.A1] <- c.A1[1]
  columnNames[columnNames.upper %in% c.A2] <- c.A2[1]
  #columnNames[columnNames.upper %in% c.EFFECT] <- c.EFFECT[1]
  #if(any(columnNames==c.EFFECT[1])) columnNames[columnNames.upper %in% c.Z] <- c.Z[1] else columnNames[columnNames.upper %in% c.Z] <- c.EFFECT[1]
  columnNames[columnNames.upper %in% c.BETA] <- c.BETA[1]
  columnNames[columnNames.upper %in% c.OR] <- c.OR[1] 
  columnNames[columnNames.upper %in% c.Z] <- c.Z[1] 
  columnNames[columnNames.upper %in% c.SE] <- c.SE[1]
  columnNames[columnNames.upper %in% c.INFO] <- c.INFO[1]
  columnNames[columnNames.upper %in% c.P] <- c.P[1]
  columnNames[columnNames.upper %in% c.N] <- c.N[1]
  columnNames[columnNames.upper %in% c.N_CAS] <- c.N_CAS[1]
  columnNames[columnNames.upper %in% c.N_CON] <- c.N_CON[1]
  columnNames[columnNames.upper %in% c.NEF] <- c.NEF[1]
  columnNames[columnNames.upper %in% c.FRQ] <- c.FRQ[1]
  columnNames[columnNames.upper %in% c.CHR] <- c.CHR[1]
  columnNames[columnNames.upper %in% c.BP] <- c.BP[1]
  
  if(stopOnMissingEssential){
    # Stop if any of these columns are not found
    if(!any(columnNames=="SNP")) stop("\nCould not find the 'SNP' column.\n")
    if(!any(columnNames=="A1")) stop("\nCould not find the 'A1' column.\n")
    if(!any(columnNames=="A2")) stop("\nCould not find the 'A2' column.\n")
  }
  
  if(!any(columnNames=="P")) warning("\nCould not find the P-value column. Standard is 'P'.\n")
  if(!any(columnNames=="BETA") & !any(columnNames=="OR" & !any(columnNames=="Z"))) warning("Could not find any effect column.\n")
  if(!any(columnNames=="SNP")) warning("\nCould not find the 'SNP' column.\n")
  if(!any(columnNames=="A1")) warning("\nCould not find the 'A1' column.\n")
  if(!any(columnNames=="A2")) warning("\nCould not find the 'A2' column.\n")
  if(!any(columnNames=="FRQ")) warning("\nCould not find the 'FRQ' column.\n")
  
  # Warn if multiple of these columns are found
  if(sum(columnNames=="SNP")>1) warning("\nMultiple 'SNP' columns found!\n")
  if(sum(columnNames=="P")>1) warning("\nMultiple 'P' columns found!\n")
  if(sum(columnNames=="A1")>1) warning("\nMultiple 'A1' columns found!\n")
  if(sum(columnNames=="A2")>1) warning("\nMultiple 'A2' columns found!\n")
  if(sum(columnNames=="BETA")>1) warning("\nMultiple 'BETA' columns found!\n")
  if(sum(columnNames=="OR")>1) warning("\nMultiple 'OR' columns found!\n")
  if(sum(columnNames=="Z")>1) warning("\nMultiple 'Z' columns found!\n")
  if(sum(columnNames=="FRQ")>1) warning("\nMultiple 'FRQ' columns found!\n")
  
  return(data.frame(std=columnNames,orig=columnNames.orig))
}

#ref, plink chromosome numbering: https://zzz.bwh.harvard.edu/plink/data.shtml
parseSNPColumnAsRSNumber <- function(text){
  #decide if BGENIE SNP format using top 100,000 SNPs
  #TODO this condition may be improved to not rely on the number of variants being >100,000
  #test
  #text<-files[[i]]$SNP
  if(sum(grepl(pattern = "^\\d+:\\w+_\\w+_\\w+", x= head(x = text, n=100000)))>90000){
    #extract and format rs-no
    indexesLengths<-regexec(pattern = "^\\d+:(\\w+)_\\w+_\\w+", text=text)
    matches<-regmatches(text,indexesLengths)
    return(lapply(X = matches, FUN = function(x)paste0("rs",x[2])))
  }
  
  text<-sub(pattern = "^XY:",replacement = "25:",x = text)
  text<-sub(pattern = "^X:",replacement = "23:",x = text)
  text<-sub(pattern = "^Y:",replacement = "24:",x = text)
  text<-sub(pattern = "^MT:",replacement = "26:",x = text)
  text<-sub(pattern = "^chr",replacement = "",x = text)
  text<-sub(pattern = "_",replacement = ":",x = text)
  
  return(text)
}

parseCHRColumn <- function(text){
  text<-sub(pattern = "^XY",replacement = "25",x = text)
  text<-sub(pattern = "^X",replacement = "23",x = text)
  text<-sub(pattern = "^Y",replacement = "24",x = text)
  text<-sub(pattern = "^MT",replacement = "26",x = text)
  text<-sub(pattern = "^chr",replacement = "",x = text)
  return(text)
}

```



# Setup common stuff for all datasets

```{r}

filePaths <- clOptions$file
traitNames <- clOptions$code
traitCodes <- clOptions$code
#test or temporary placeholders
filePaths<-c("/Users/jakz/Documents/local_db/JZ_GED_PHD_ADMIN_GENERAL/data/gwas_sumstats/cleaned/ADHD05.gz")
traitNames<-c("ADHD 1")
traitCodes<-c("ADHD05")
sumstats.meta<-data.table(name=traitNames)
row.names(sumstats.meta)<-traitCodes
```

# Read in sumstats and interpret columns
## Read in sumstats

```{r read in sumstats}

#TODO replace commas with field separators as in Helena's script

cCode <- traitCodes[1]
cFilePath <- filePaths[1] #we will probably want to have a loop over the provided files
cSumstats <- read.table(cFilePath,header=T, quote="\"",fill=T,na.string=c(".",NA,"NA",""))

#number of rows before touching the data
nRowsRaw <- nrow(cSumstats)
sumstats.meta[cCode,c("n_snp_raw")]<-nRowsRaw

```

## Interpret columns

Check the existance of columns

Rename columns to standardised names

```{r interpret columns}

newNames <- stdGwasColumnNames(columnNames = colnames(cSumstats))
print(newNames)
colnames(cSumstats) <- newNames$std

```

# Column and dataframe re-formatting

## Re-format and parse special format columns
Set correct R data formats

Transform to data table

Clean or fix variant SNP column

Interpret BGENIE SNP format

Interpret daner like format

```{r re-format columns}
#convert to data frame
cSumstats <- setDT(cSumstats)

# Column harmonisation
cSumstats.keys <- c('SNP')
cSumstats$SNP <- as.character(cSumstats$SNP)
cSumstats$A1 <- toupper(as.character(cSumstats$A1))
cSumstats$A2 <- toupper(as.character(cSumstats$A2))

#parse SNP if needed
cSumstats$SNP <- tolower(parseSNPColumnAsRSNumber(cSumstats$SNP))

if(any(colnames(cSumstats)=="CHR")) {
  cSumstats$CHR <- toupper(as.character(cSumstats$CHR))
  cSumstats.keys <- c(cSumstats.keys,'CHR')
}

if(any(colnames(cSumstats)=="BP")) {
  cSumstats$BP <- as.integer(cSumstats$BP)
  cSumstats.keys <- c(cSumstats.keys,'BP')
}

#set data table index on selected keys
setkeyv(cSumstats,cols = cSumstats.keys)


#check if daner like columns present
# ref: https://docs.google.com/document/d/1TWIhr8-qpCXB13WCXcU1_HDio8lC_MeWoAg2jlggrtU/edit
if(!any(colnames(cSumstats)=="FRQ") & !any(colnames(cSumstats)=="N_CAS") & !any(colnames(cSumstats)=="N_CON")){
  danerNcas<-colnames(cSumstats)[startsWith(colnames(cSumstats),prefix = "FRQ_A_")][1]
  danerNcon<-colnames(cSumstats)[startsWith(colnames(cSumstats),prefix = "FRQ_U_")][1]
  if(!is.na(danerNcas) & !is.na(danerNcon)){
    #add number of cases and number of controls
    cSumstats$N_CAS <- danerNcas
    cSumstats$N_CON <- danerNcon
    #add case and control specific effect allele frequencies
    colnames(cSumstats)[danerNcas] <- "FRQ_CASES"
    colnames(cSumstats)[danerNcon] <- "FRQ_CONTROLS"
  }
  
}


```

## Add missing columns

Set N from Ncon and Ncas

Set N from argument

Add columns on sample size, enough for PRS enough for pathway analysis

```{r add missing columns}

# Save original Z
if(any(colnames(cSumstats)=="Z")){
  cSumstats$Z_ORIG<-cSumstats$Z
}

# Add total N depending on columns and input
if(any(colnames(cSumstats)=="N_CAS") && any(colnames(cSumstats)=="N_CON")) {
  ### Calculate total N from number of cases and number of controls if they are present. Overwrite any specific total N.
  cSumstats$N <- cSumstats$N_CAS + cSumstats$N_CON
} else if(!is.null(cN)) {
  cSumstats$N[which(is.na(cSumstats$N))]<-cN #default behaviour - add explicit N only to missing values.
} else if(!any(colnames(cSumstats)=="N")) {
  warning("\nNo N column detected!\n")
  sumstats.meta[cCode,c("noN")]<-T
}

#Add metadata about enough for PRS and pathway analysis
sumstats.meta[cCode,c("enough_PRS")]<-any(colnames(cSumstats)=="SNP") & any(colnames(cSumstats)=="P") & (any(colnames(cSumstats)=="BETA") | any(colnames(cSumstats)=="OR") | any(colnames(cSumstats)=="Z") ) & any(colnames(cSumstats)=="A1") & any(colnames(cSumstats)=="A2")
sumstats.meta[cCode,c("enough_pathwayanalysis")]<-any(colnames(cSumstats)=="SNP") & any(colnames(cSumstats)=="P")

```


# Cleaning

##Missing data

Remove variants with missing values

```{r clean missing data}

#clean missing P
if(any(colnames(cSumstats)=="P")){
  cond <- is.na(cSumstats$P)
  sumstats.meta[cCode,c("n_removed_missing_p")]<-sum(cond)
  cSumstats<-cSumstats[which(!cond),]
}

#clean missing effect
if(any(colnames(cSumstats)=="BETA")){
  cond <- is.na(cSumstats$BETA)
  sumstats.meta[cCode,c("n_removed_missing_effect")]<-sum(cond)
  cSumstats<-cSumstats[which(!cond),]
} else if(any(colnames(cSumstats)=="OR")) {
  cond <- is.na(cSumstats$OR)
  sumstats.meta[cCode,c("n_removed_missing_effect")]<-sum(cond)
  cSumstats<-cSumstats[which(!cond),]
} else if(any(colnames(cSumstats)=="Z")) {
  cond <- is.na(cSumstats$Z)
  sumstats.meta[cCode,c("n_removed_missing_effect")]<-sum(cond)
  cSumstats<-cSumstats[which(!cond),]
}

#indels
if(keepIndel == T){
  cSumstats$A1 <- as.character(toupper(cSumstats$A1))
  cSumstats$A2 <- as.character(toupper(cSumstats$A2))
} else if(keepIndel == F){
  cSumstats$A1 <- as.character(toupper(cSumstats$A1), c("A", "C", "G", "T"))
  cSumstats$A2 <- as.character(toupper(cSumstats$A2), c("A", "C", "G", "T"))
  cond <- is.na(cSumstats$A1) | is.na(cSumstats$A2)
  sumstats.meta[cCode,c("n_removed_indels")]<-sum(cond)
  cSumstats<-cSumstats[which(!cond),]
}

```


## Duplicate data

Deal with duplicate variants

```{r clean duplicate data}
# Remove duplicated variants across SNP, A1 and A2
if(any(colnames(cSumstats)=="SNP") & any(colnames(cSumstats)=="A1") & any(colnames(cSumstats)=="A2")) {
  cSumstats.n <- nrow(cSumstats)
  cSumstats <- unique(cSumstats,by = c("SNP","A1","A2"))
  umstats.meta[cCode,c("n_removed_duplicates")]<-cSumstats.n-nrow(cSumstats)
}
```









?Remove variants based on MAF/FRQ, INFO, OR, p-value, N (Ollies script) filters etc



Deal with maf and frequencey columns

Deal with missing effect standard error
Add standard errors from beta & z or or & z (Ollies script)







Check and correct for GC



?Read in reference from plink formats
```{r read in reference}

```

2) Read in Up to date table with full GWAS information of each trait. Currently in csv format linked with the flask app, or in the google sheet.
```{r read in full GWAS info all traits}

```

```{r check mhc removed }

```

```{r check traits significantly h2}

```

3) Read in rg data for your trait of interest\
```{r read in rg results}

```

```{r select rg results from log out put files}

```

2) Joining datasets:
#Step) join the rg results with the GWAS information file to get full GWAS info for each trait
Merge 
```{r join info GWAS sheet with rg results}

```

3) Filtering
For both summary table for plotting and supplementary table:
#step) Only extract GWAS traits that are not private. 
Filter by permissions and exclude all private sumstats
NOTE: need to simplify the current permissions category 
```{r filter based on permissions}

```

```{r by trait cateogry}

```

#step) Filter p-values by bonferonni threshold 
Adapt Helena's script in python that already exists calculating bonferonni significance?
Create a new data frame with only bonf signif traits for summary table for paper plotting of top traits? or just add a new column with 'yes/no' for bonferonnni significant? Johan's preference: stick to one dataframe and filter in the plotting step
For supplementary table: how do we want to indicate which traits are bonferonni significant? e.g. bold text? A separate column saying 'significant/ non significant'? Colours??
```{r create bonferonni column}

```

```{r create FDR column }

```

```{r convert table to matrix for matrix decomposition}

```

note: we already have this script in python
```{r matrix decomposition for bonferonni threshold}

```

Create new dataframes for supplmentary tables

#create supplementary tables
Select columns for supplementary tables for paper. Decide on columns. 
e.g. Watson et al 2019 (AN GWAS) columns: Phenotype, rg, se, P (green = bonferoni significant), Phenotype category, PMID, code, ancestry. 
but could also include Z value of rg, gcov_int, gcov_int_se, h2_obs, h2_obs_se, h2_int	h2_int_se - or h2 Z and mean chi square which could be useful? Topher has a script that extracted h2 information for each GWAS
```{r create dataframe for supplementary tables}

```

4) Saving new tables
#what is the preffered format for saving the new table? google sheets? excel sheet for supplementary materials? Save summary table as rds for plotting?
Save as excel, google sheets, txt
```{r save supplementary table}

```

5) Plotting
Decide on significance threshold for plotting. Note: matrix decomposition threshold as less stringent.

Note: trait labels for plotting. This needs to be added to in the google spreadsheet, and then trait labels column for plotting will be used in stead of 'phenotype'

We also have multiple GWAS for one phenotype e.g. MDD - 
```{r vector of signficant traits for plotting}
# i.e. the researcher may only want to show specific GWAS for each phenotype e.g. most powerful, or certain cohorts, selected based on type of phenotyping. A
```


```{r filter based on vector of traits}

```


```{r create dataframe for plotting}
#filtering: 1) matrix decomposition 2) vector of selected traits for plotting
```

Use AN GWAS plot script (Watson et al 2019)
```{r plot rg results}

```

Publication table
```{r dataframe for publication table of significant rg traits}

```

save in excel format
```{r save publication table}

```
 
What output do we want from this script?
1) a general filtered summary table with full GWAS information for each trait (permissions, column significant)
2) an rg plot with top traits
3) a supplementary table with selected columns for paper (all traits, except traits with private permissions)
note: at some point we want to filter by heritability. But do we want this at an earlier step so that we are not running rg with traits that aren't significantly heritable?
4) Publication table - significant ones (instead of a plot)

